# train_model.py
import os
import sys
import argparse
import pandas as pd
import pickle
import numpy as np
from sklearn.ensemble import IsolationForest

# ---------------------------------------------------------
# PATH AYARLARI
# ---------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../"))
sys.path.append(project_root)

# ---------------------------------------------------------
# FEATURE EXTRACTOR
# ---------------------------------------------------------
try:
    from src.core.ml.feature_extractor import extract, vectorize, FEATURE_ORDER
except ImportError:
    print("KRÄ°TÄ°K HATA: feature_extractor bulunamadÄ±!")
    sys.exit(1)


def train(data_path: str, output_path: str):
    print(f"[*] Veri seti okunuyor: {data_path}")

    if not os.path.exists(data_path):
        print(f"HATA: Dataset bulunamadÄ±: {data_path}")
        sys.exit(1)

    df = pd.read_csv(data_path)

    if df.empty:
        print("HATA: Dataset boÅŸ!")
        sys.exit(1)

    print(f"[*] Toplam {len(df)} satÄ±r yÃ¼klendi")
    print(f"[*] Feature order: {FEATURE_ORDER}")

    X = []

    print("[*] Feature extraction baÅŸlÄ±yor...")
    for _, row in df.iterrows():
        row_dict = row.to_dict()
        feature_dict = extract(event=row_dict, state=row_dict)
        vector = vectorize(feature_dict)
        X.append(vector)

    X = np.array(X)
    print(f"[*] Feature matrix hazÄ±r: {X.shape}")

    print("[*] IsolationForest eÄŸitiliyor...")
    clf = IsolationForest(
        n_estimators=100,
        contamination=0.1,
        random_state=42,
        n_jobs=-1
    )
    clf.fit(X)

    # -----------------------------
    # MODEL BUNDLE (KRÄ°TÄ°K)
    # -----------------------------
    bundle = {
        "model": clf,
        "feature_order": FEATURE_ORDER,
        "contamination": 0.1
    }

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "wb") as f:
        pickle.dump(bundle, f)

    print("\n" + "-" * 60)
    print("âœ… MODEL BAÅžARIYLA EÄžÄ°TÄ°LDÄ°")
    print(f"ðŸ“‚ Model yolu          : {output_path}")
    print(f"ðŸ“Š EÄŸitim Ã¶rnek sayÄ±sÄ± : {len(df)}")
    print("-" * 60 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="EVSE Anomaly Detection - Model Trainer"
    )

    parser.add_argument(
        "--data",
        type=str,
        default="data/dataset_from_logs.csv",
        help="EÄŸitim dataset (CSV)"
    )

    parser.add_argument(
        "--out",
        type=str,
        default="src/core/models/model.pkl",
        help="Ã‡Ä±ktÄ± model dosyasÄ±"
    )

    args = parser.parse_args()

    train(args.data, args.out)
