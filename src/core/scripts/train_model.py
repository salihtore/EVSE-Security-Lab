import os
import sys
import argparse
import pandas as pd
import pickle
import numpy as np
from sklearn.ensemble import IsolationForest

# ---------------------------------------------------------
# PATH AYARLARI
# ---------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../"))
sys.path.append(project_root)

# ---------------------------------------------------------
# KADÄ°R'Ä°N MODÃœLLERÄ°NÄ° IMPORT ET
# ---------------------------------------------------------
try:
    from src.core.ml.feature_extractor import extract, vectorize, FEATURE_ORDER
except ImportError as e:
    print("KRÄ°TÄ°K HATA: Feature Extractor bulunamadÄ±!")
    print("Kadir'in dosyasÄ±nÄ±n 'src/core/ml/feature_extractor.py' olduÄŸundan emin ol.")
    sys.exit(1)

def train(data_path, output_path):
    print(f"[*] Veri seti okunuyor: {data_path}")
    
    # Dataset dosyasÄ±nÄ± kontrol et ve oku
    if not os.path.exists(data_path):
        print(f"HATA: '{data_path}' dosyasÄ± bulunamadÄ±.")
        sys.exit(1)
        
    df = pd.read_csv(data_path)
    
    if len(df) == 0:
        print("HATA: Veri seti boÅŸ!")
        sys.exit(1)

    print(f"[*] Toplam {len(df)} satÄ±r veri iÅŸlenecek.")
    print(f"[*] KullanÄ±lan Feature SÄ±rasÄ±: {FEATURE_ORDER}")

    X = []
    
    print("[*] Veriler vektÃ¶rleÅŸtiriliyor...")
    
    for index, row in df.iterrows():
        # Her satÄ±rdan event/state verilerini hazÄ±rla
        # CSV dÃ¼z olduÄŸu iÃ§in satÄ±rÄ± hem event hem state yerine kullanÄ±yoruz.
        row_dict = row.to_dict()
        feature_dict = extract(event=row_dict, state=row_dict)
        
        # Feature vektÃ¶rÃ¼nÃ¼ oluÅŸtur
        vector = vectorize(feature_dict)
        X.append(vector)

    X = np.array(X)
    print(f"[*] EÄŸitim verisi hazÄ±r. Matris Boyutu: {X.shape}")

    # IsolationForest modelini eÄŸit
    print("[*] IsolationForest modeli eÄŸitiliyor...")
    clf = IsolationForest(
        n_estimators=100, 
        contamination=0.1, 
        random_state=42, 
        n_jobs=-1
    )
    clf.fit(X)

    # Modeli kaydet
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    with open(output_path, 'wb') as f:
        pickle.dump(clf, f)
        
    print("-" * 50)
    print(f"âœ… [BAÅARILI] Model eÄŸitildi ve kaydedildi.")
    print(f"ğŸ“‚ KayÄ±t Yeri: {output_path}")
    print("-" * 50)

if __name__ == "__main__":
    # CLI argÃ¼manlarÄ±nÄ± ayarla
    parser = argparse.ArgumentParser(description="EVSE Anomaly Detection - Model Trainer")
    
    parser.add_argument(
        '--data', 
        type=str, 
        default='data/dataset.csv', 
        help='EÄŸitim verisi (CSV)'
    )
    
    parser.add_argument(
        '--out', 
        type=str, 
        default='src/core/models/anomaly_model.pkl', 
        help='Ã‡Ä±ktÄ± model dosyasÄ± (.pkl)'
    )

    args = parser.parse_args()

    train(args.data, args.out)
